from fingerprintgenerator import FingerprintGenerator
from nlp_module import run_nlp
from news_normalizer import NewsNormalizer
from graph_exporter import GraphExporter
from collections import defaultdict
from itertools import combinations  # ADICIONE ESTA IMPORTACAO
import os
import pandas as pd
import random  # ADICIONE TAMBÃ‰M O RANDOM

def load_news_from_csv(csv_path, sample_frac=0.2):
    """Carrega notÃ­cias de um CSV"""
    try:
        print(f"ğŸ“– Lendo {csv_path}...")
        df = pd.read_csv(csv_path)
        sampled_df = df.sample(frac=sample_frac, random_state=42)
        
        texts = []
        filenames = []
        labels = []
        for idx, row in sampled_df.iterrows():
            combined_text = f"{row['title']} {row['text']}"
            texts.append(combined_text)
            filenames.append(f"{os.path.basename(csv_path)}_{idx}")
            labels.append(1 if "Fake" in csv_path else 0)
        
        print(f"   âœ… Carregadas {len(texts)} notÃ­cias de {csv_path}")
        return texts, filenames, labels
    except Exception as e:
        print(f"âš ï¸ Erro ao carregar {csv_path}: {e}")
        return [], [], []

def main():
    true_path = "True.csv"
    fake_path = "Fake.csv"

    # Verificar se os arquivos existem
    print("ğŸ” Verificando arquivos...")
    if not os.path.exists(true_path):
        print(f"âŒ Arquivo {true_path} nÃ£o encontrado!")
        return
    if not os.path.exists(fake_path):
        print(f"âŒ Arquivo {fake_path} nÃ£o encontrado!")
        return

    print("âœ… Arquivos encontrados!")

    # Carregar dados
    print("\nğŸ“‚ Carregando notÃ­cias...")
    true_texts, true_filenames, true_labels = load_news_from_csv(true_path, 0.2)
    fake_texts, fake_filenames, fake_labels = load_news_from_csv(fake_path, 0.2)

    texts = true_texts + fake_texts
    filenames = true_filenames + fake_filenames
    labels = true_labels + fake_labels

    print(f"\nğŸ“Š Total de arquivos carregados: {len(texts)}")

    if len(texts) == 0:
        print("âŒ Nenhuma notÃ­cia carregada.")
        return

    # NormalizaÃ§Ã£o
    print("\nğŸ”„ Normalizando textos...")
    normalizer = NewsNormalizer()
    normalized_texts = [normalizer.normalize_news(t) for t in texts]
    
    # Gerar fingerprints
    print("ğŸ”‘ Gerando fingerprints...")
    fp_gen = FingerprintGenerator(hash_sizes=[64])
    fingerprints = [fp_gen.generate_simhash(t, 64) for t in normalized_texts]
    
    # --- SEÃ‡ÃƒO OTIMIZADA: CRIAR GRAFOS ---
    print("\nğŸ•¸ï¸ Criando grafo de similaridade (OTIMIZADO)...")
    graph_exporter = GraphExporter()
    
    # OpÃ§Ã£o 1: K-NN (MAIS RÃPIDA E EFICIENTE) - RECOMENDADA
    edges_count = graph_exporter.create_similarity_graph_knn(
        texts=texts,
        fingerprints=fingerprints,
        labels=labels,
        filenames=filenames,
        k_neighbors=15,  # ConexÃµes por nÃ³
        threshold=20     # DistÃ¢ncia mÃ¡xima
    )
    
    # Exportar para Gephi
    nodes_count, edges_count = graph_exporter.export_for_gephi("gephi_news_network")
    
    print(f"ğŸ“Š EstatÃ­sticas do Grafo:")
    print(f"   - NÃ³s (notÃ­cias): {nodes_count}")
    print(f"   - Arestas (similaridades): {edges_count}")
    if nodes_count > 1:
        density = edges_count / (nodes_count * (nodes_count - 1) / 2)
        print(f"   - Densidade: {density:.6f}")
    else:
        print(f"   - Densidade: N/A (apenas 1 nÃ³)")
    
    # --- FIM DA SEÃ‡ÃƒO DE GRAFOS ---
    
    # CÃ¡lculo de distÃ¢ncias (opcional, mas mais leve)
    print("\nğŸ“ Calculando distÃ¢ncias de Hamming (amostra)...")
    sample_size = min(100, len(fingerprints))
    if len(fingerprints) > 1:
        # CorreÃ§Ã£o: usar combinations diretamente jÃ¡ que foi importado
        sample_pairs = random.sample(list(combinations(range(len(fingerprints)), 2)), sample_size)
        distances = [bin(fingerprints[i] ^ fingerprints[j]).count("1") for i, j in sample_pairs]
        avg_distance = sum(distances) / len(distances)
        print(f"   DistÃ¢ncia mÃ©dia de Hamming (amostra de {sample_size} pares): {avg_distance:.2f}")
    else:
        print("   NÃ£o hÃ¡ fingerprints suficientes para calcular distÃ¢ncias")

    # ClassificaÃ§Ã£o
    print("\nğŸ” Classificando notÃ­cias...")
    nlp_results = [run_nlp(t) for t in texts]

    # Agrupar resultados por tipo (True/Fake)
    results_by_type = defaultdict(list)
    for filename, (pred, conf, used_hamming) in zip(filenames, nlp_results):
        file_type = "True" if "True" in filename else "Fake"
        results_by_type[file_type].append((filename, pred, conf, used_hamming))

    # Determinar tamanho mÃ¡ximo do nome do arquivo
    max_len = max((len(file) for file in filenames), default=0)

    # Exibir resultados
    print("\nğŸ“Š RESULTADOS DA CLASSIFICAÃ‡ÃƒO:")
    for file_type, files in results_by_type.items():
        print(f"\nğŸ“‚ {file_type} News")
        for file, pred, conf, used_hamming in files:
            symbol = "âŒ" if pred == 1 else "âœ…"
            pred_text = "FAKE" if pred == 1 else "TRUE"
            
            if used_hamming:
                print(f"\tğŸ“„ {file:<{max_len}} --> {symbol} {pred_text} *H")
            else:
                print(f"\tğŸ“„ {file:<{max_len}} --> {symbol} {pred_text} (ConfianÃ§a: {conf:6.2%})")

    # EstatÃ­sticas gerais
    total_files = len(texts)
    fake_count = sum(1 for pred, _, _ in nlp_results if pred == 1)
    true_count = total_files - fake_count
    
    print(f"\nğŸ“ˆ ESTATÃSTICAS GERAIS:")
    print(f"Total de notÃ­cias analisadas: {total_files}")
    print(f"NotÃ­cias classificadas como TRUE: {true_count} ({true_count/total_files*100:.2f}%)")
    print(f"NotÃ­cias classificadas como FAKE: {fake_count} ({fake_count/total_files*100:.2f}%)")

    # Verificar acurÃ¡cia bÃ¡sica
    correct_predictions = 0
    for filename, (pred, _, _) in zip(filenames, nlp_results):
        true_label = 1 if "Fake" in filename else 0
        if pred == true_label:
            correct_predictions += 1
    
    accuracy = correct_predictions / total_files if total_files > 0 else 0
    print(f"ğŸ¯ AcurÃ¡cia geral: {accuracy:.2%}")

if __name__ == "__main__":
    main()